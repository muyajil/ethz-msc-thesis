{
    "optimizers": [
        "adam",
        "adagrad",
        "momentum",
        "sgd"
    ],
    "loss_functions": [
        "top_1",
        "cross_entropy"
    ],
    "learning_rates": [
        0.1,
        0.05,
        0.01,
        0.005,
        0.001,
        0.0005,
        0.0001
    ],
    "batch_sizes":[
        50,
        100,
        200
    ]
}