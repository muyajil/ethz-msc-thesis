{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from hgru4rec.user_par_mini_batch import input_fn, UserParallelMiniBatchDataset\n",
    "from tensorflow.contrib.cudnn_rnn import CudnnGRU\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['num_units_session'] = 25\n",
    "params['num_units_user'] = 50\n",
    "params['num_products'] = 2600000\n",
    "params['embedding_size'] = 25\n",
    "params['user_rnn_layers'] = 2\n",
    "params['user_rnn_units'] = 50\n",
    "params['session_rnn_layers'] = 2\n",
    "params['session_rnn_units'] = 25\n",
    "params['num_negative_samples'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# get datapoint iterator\n",
    "dataset = input_fn(10, 'gs://ma-muy/baseline_dataset/sessions_by_user/', 3, epochs=2)\n",
    "datapoints = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UserId': <tf.Tensor: id=1209, shape=(10,), dtype=int64, numpy=\n",
       " array([ 514600, 2130900, 3111300, 1140200, 2497600, 1234000,  377000,\n",
       "        3035900, 1309300,  348600])>,\n",
       " 'ProductId': <tf.Tensor: id=1207, shape=(10,), dtype=int64, numpy=\n",
       " array([     -1, 5765285, 5631179, 4684774,      -1, 2581879,  437249,\n",
       "        6045207,  708882, 5884728])>,\n",
       " 'EmbeddingId': <tf.Tensor: id=1206, shape=(10,), dtype=int64, numpy=array([-1, 21, 22, 23, -1,  5, 24, 25, 19, 26])>,\n",
       " 'UserEmbeddingId': <tf.Tensor: id=1208, shape=(10,), dtype=int64, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoint = next(datapoints)\n",
    "features, labels = datapoint\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = features['UserId'].shape[0]\n",
    "\n",
    "# Mask describing ended sessions, true if session ended\n",
    "ended_sessions_mask = tf.get_variable(\n",
    "    'ended_sessions_mask',\n",
    "    shape=(batch_size,),\n",
    "    initializer=tf.zeros_initializer(),\n",
    "    trainable=False,\n",
    "    dtype=tf.bool)\n",
    "\n",
    "# Mask describing ending sessions, true if session is ending\n",
    "ending_sessions_mask = tf.get_variable(\n",
    "    'ending_sessions_mask',\n",
    "    shape=(batch_size,),\n",
    "    initializer=tf.zeros_initializer(),\n",
    "    trainable=False,\n",
    "    dtype=tf.bool)\n",
    "\n",
    "# Mask describing ended users, true if not more user events\n",
    "ended_users_mask = tf.get_variable(\n",
    "    'ended_users_mask',\n",
    "    shape=(batch_size,),\n",
    "    initializer=tf.zeros_initializer(),\n",
    "    trainable=False,\n",
    "    dtype=tf.bool)\n",
    "\n",
    "# Hidden states of session_rnn\n",
    "session_hidden_states = tf.get_variable(\n",
    "    'session_hidden_states',\n",
    "    shape=(batch_size, params['session_rnn_units']),\n",
    "    initializer=tf.zeros_initializer())\n",
    "\n",
    "# User hidden_states, updated by user_rnn\n",
    "user_hidden_states = tf.get_variable(\n",
    "    'user_hidden_states',\n",
    "    shape=(batch_size, params['user_rnn_units']),\n",
    "    initializer=tf.zeros_initializer()\n",
    ")\n",
    "\n",
    "# Softmax weights to map RNN output to product space\n",
    "softmax_weights = tf.get_variable(\n",
    "    'softmax_weights',\n",
    "    shape=(params['num_products'], params['session_rnn_units']))\n",
    "\n",
    "# Biases for above\n",
    "softmax_biases = tf.get_variable(\n",
    "    'softmax_biases',\n",
    "    shape=(params['num_products'],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rnn = GRU(\n",
    "    # params['user_rnn_layers'],\n",
    "    params['user_rnn_units'],\n",
    "    return_state=True,\n",
    "    implementation=2,\n",
    "    dropout=0.1,\n",
    "    name='user_rnn')\n",
    "\n",
    "session_rnn = GRU(\n",
    "    # params['session_rnn_layers'],\n",
    "    params['session_rnn_units'],\n",
    "    return_state=True,\n",
    "    implementation=2,\n",
    "    dropout=0.2,\n",
    "    name='session_rnn')\n",
    "\n",
    "# Layer to predict new session initialization\n",
    "user2session_layer = Dense(\n",
    "    params['session_rnn_units'],\n",
    "    input_shape=(params['user_rnn_units'],),\n",
    "    activation='tanh',\n",
    "    name='user2session_layer')\n",
    "\n",
    "# Dropout layer for session initialization\n",
    "user2session_dropout = Dropout(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Session Hidden States to 0 for new users\n",
    "session_hidden_states = tf.where(\n",
    "    ended_users_mask,\n",
    "    tf.zeros(tf.shape(session_hidden_states)),\n",
    "    session_hidden_states,\n",
    "    name='reset_session_hidden_states')\n",
    "\n",
    "# Reset User Hidden States to 0 for new users\n",
    "user_hidden_states = tf.where(\n",
    "    ended_users_mask,\n",
    "    tf.zeros(tf.shape(user_hidden_states)),\n",
    "    user_hidden_states,\n",
    "    name='reset_user_hidden_states'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute new user representation for all users in current batch\n",
    "new_session_hidden_states_seed, new_user_hidden_states = user_rnn.apply(\n",
    "    tf.expand_dims(session_hidden_states, 1),\n",
    "    initial_state=user_hidden_states)\n",
    "\n",
    "# Predict new session initialization for next session\n",
    "new_session_hidden_states = user2session_layer.apply(\n",
    "    new_session_hidden_states_seed)\n",
    "\n",
    "new_session_hidden_states = user2session_dropout.apply(\n",
    "    new_session_hidden_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select new session initialization for new sessions\n",
    "session_hidden_states = tf.where(\n",
    "    ended_sessions_mask,\n",
    "    new_session_hidden_states,\n",
    "    session_hidden_states,\n",
    "    name='initialize_new_sessions')\n",
    "\n",
    "# Update user hidden states where the session ended\n",
    "user_hidden_states = tf.where(\n",
    "    ended_sessions_mask,\n",
    "    new_user_hidden_states,\n",
    "    user_hidden_states,\n",
    "    name='update_user_representation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute new mask for ended sessions\n",
    "ended_sessions_mask = tf.cast(\n",
    "    tf.where(\n",
    "        tf.equal(features['ProductId'], -1),\n",
    "        tf.ones(tf.shape(ended_sessions_mask)),\n",
    "        tf.zeros(tf.shape(ended_sessions_mask)),\n",
    "        name='compute_ended_sessions'),\n",
    "    tf.bool)\n",
    "\n",
    "# Compute new mask for ending sessions\n",
    "ending_sessions_mask = tf.cast(\n",
    "    tf.where(\n",
    "        tf.equal(labels['ProductId'], -1),\n",
    "        tf.ones(tf.shape(ending_sessions_mask)),\n",
    "        tf.zeros(tf.shape(ending_sessions_mask)),\n",
    "        name='compute_ending_sessions'),\n",
    "    tf.bool)\n",
    "\n",
    "# Compute new mask for ended users\n",
    "ended_users_mask = tf.cast(\n",
    "    tf.where(\n",
    "        tf.equal(features['UserId'], -1),\n",
    "        tf.ones(tf.shape(ended_users_mask)),\n",
    "        tf.zeros(tf.shape(ended_users_mask)),\n",
    "        name='compute_ended_users'),\n",
    "    tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant sessions have not ended and do not end in the next step\n",
    "relevant_sessions_mask = tf.logical_not(\n",
    "    tf.logical_or(\n",
    "        ended_sessions_mask,\n",
    "        ending_sessions_mask))\n",
    "\n",
    "# Get one-hot encoding of products\n",
    "relevant_one_hots = tf.map_fn(\n",
    "    lambda x: tf.cond(\n",
    "        x[1],\n",
    "        lambda: tf.one_hot(x[0], params['num_products']),\n",
    "        lambda: tf.zeros(params['num_products'])\n",
    "    ),\n",
    "    [\n",
    "        features['EmbeddingId'],\n",
    "        relevant_sessions_mask\n",
    "    ],\n",
    "    dtype=tf.float32,\n",
    "    name='get_relevant_one_hots')\n",
    "\n",
    "# Get session hidden states for relevant sessions\n",
    "relevant_hidden_states = tf.where(\n",
    "    relevant_sessions_mask,\n",
    "    session_hidden_states,\n",
    "    tf.zeros(tf.shape(session_hidden_states)),\n",
    "    name='get_relevant_session_hidden_states'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Session RNN -> get new hidden states and predictions\n",
    "predictions, new_session_hidden_states = session_rnn.apply(\n",
    "    tf.expand_dims(relevant_one_hots, 1),\n",
    "    initial_state=relevant_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out irrelevant predictions\n",
    "predictions = tf.boolean_mask(\n",
    "    predictions,\n",
    "    relevant_sessions_mask,\n",
    "    name='filter_irrelevant_predictions')\n",
    "\n",
    "# Update session hidden states for relevant sessions\n",
    "session_hidden_states = tf.where(\n",
    "    relevant_sessions_mask,\n",
    "    new_session_hidden_states,\n",
    "    session_hidden_states,\n",
    "    name='update_relevant_session_hidden_states')\n",
    "\n",
    "# Extract relevant labels\n",
    "relevant_labels = tf.boolean_mask(\n",
    "    labels['EmbeddingId'],\n",
    "    relevant_sessions_mask,\n",
    "    name='filter_irrelevant_labels')\n",
    "\n",
    "# Compute logits for product predictions\n",
    "logits = tf.matmul(\n",
    "    predictions,\n",
    "    softmax_weights,\n",
    "    transpose_b=True) + softmax_biases\n",
    "\n",
    "# Apply softmax activation\n",
    "softmax_predictions = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1184, shape=(2,), dtype=int32, numpy=array([     10, 2600000], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(softmax_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Hitrate\n",
    "\n",
    "in_top_k = tf.nn.in_top_k(softmax_predictions, relevant_labels, 5)\n",
    "hitrate = tf.divide(\n",
    "    tf.reduce_sum(tf.cast(in_top_k, tf.int64)),\n",
    "    tf.shape(labels)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Loss Function\n",
    "\n",
    "negative_samples_weights = tf.nn.embedding_lookup(softmax_weights, relevant_labels)\n",
    "negative_samples_biases = tf.nn.embedding_lookup(softmax_biases, relevant_labels)\n",
    "\n",
    "logits = tf.matmul(predicted_embeddings, negative_samples_weights, transpose_b=True) + negative_samples_biases\n",
    "yhat = tf.nn.softmax(logits) # for each of the examples in the batch we select the remainder of the minibatch as negative examples\n",
    "\n",
    "# TOP 1 Loss function\n",
    "yhatT = tf.transpose(yhat)\n",
    "term1 = tf.reduce_mean(tf.nn.sigmoid(-tf.diag_part(yhat)+yhatT)+tf.nn.sigmoid(yhatT**2), axis=0)\n",
    "term2 = tf.nn.sigmoid(tf.diag_part(yhat)**2) / batch_size.value\n",
    "loss = tf.reduce_mean(term1 - term2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2867, shape=(), dtype=float32, numpy=0.9640579>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "`loss` passed to Optimizer.compute_gradients should be a function when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-c9a5cbb247ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/code-JIyQgSPM/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/code-JIyQgSPM/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m       raise RuntimeError(\n\u001b[0;32m--> 481\u001b[0;31m           \u001b[0;34m\"`loss` passed to Optimizer.compute_gradients should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m           \"be a function when eager execution is enabled.\")\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `loss` passed to Optimizer.compute_gradients should be a function when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op = optimizer.minimize(loss, global_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=639, shape=(10, 25), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_hidden_states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
