{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from hgru4rec.user_par_mini_batch import input_fn, UserParallelMiniBatchDataset\n",
    "from tensorflow.contrib.cudnn_rnn import CudnnGRU\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([1,2,3, 6])\n",
    "b = tf.constant([[0,1,2,3,4,5],[0,1,2,3,4,5],[0,1,2,3,4,5], [0,1,2,3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=10, shape=(4,), dtype=int32, numpy=array([0, 0, 0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=65, shape=(4, 6), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1],\n",
       "       [2, 2, 2, 2, 2, 2],\n",
       "       [3, 3, 3, 3, 3, 3],\n",
       "       [6, 6, 6, 6, 6, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.broadcast_to(tf.expand_dims(a, 1), tf.shape(b))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=112, shape=(3,), dtype=int64, numpy=array([1, 2, 3])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.where(tf.equal(b, c))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['num_units_session'] = 25\n",
    "params['num_units_user'] = 50\n",
    "params['num_products'] = 542346\n",
    "params['num_users'] = 307526\n",
    "params['embedding_size'] = 25\n",
    "params['user_rnn_layers'] = 2\n",
    "params['user_rnn_units'] = 50\n",
    "params['session_rnn_layers'] = 2\n",
    "params['session_rnn_units'] = 25\n",
    "params['num_negative_samples'] = 10\n",
    "params['user_dropout'] = 0.1\n",
    "params['session_dropout'] = 0.1\n",
    "params['init_dropout'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# get datapoint iterator\n",
    "dataset = input_fn(10, 'gs://ma-muy/baseline_dataset/train/', epochs=2)\n",
    "datapoints = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UserId': <tf.Tensor: id=467, shape=(10,), dtype=int64, numpy=\n",
       " array([ 581100,  511700, 1966800, 1515200, 2183900,  542600, 2873000,\n",
       "         481700,  567900, 2665400])>,\n",
       " 'ProductId': <tf.Tensor: id=463, shape=(10,), dtype=int64, numpy=\n",
       " array([7952040, 5689559, 5803018, 8058320,  403209, 2488589, 6077646,\n",
       "        6303063, 7026663, 6195320])>,\n",
       " 'EmbeddingId': <tf.Tensor: id=461, shape=(10,), dtype=int64, numpy=\n",
       " array([   481,  64629,  71234,  83366,  26995,  35369, 110108,  16427,\n",
       "         75069,  43262])>,\n",
       " 'UserEmbeddingId': <tf.Tensor: id=466, shape=(10,), dtype=int64, numpy=array([1645, 1681,  697, 1008,  133,  482, 2594, 1705,  783, 1389])>,\n",
       " 'SessionChanged': <tf.Tensor: id=464, shape=(10,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 1, 0, 0, 0, 1])>,\n",
       " 'LastSessionEvent': <tf.Tensor: id=462, shape=(10,), dtype=int64, numpy=array([0, 1, 0, 0, 0, 0, 1, 0, 0, 0])>,\n",
       " 'UserChanged': <tf.Tensor: id=465, shape=(10,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoint = next(datapoints)\n",
    "features, labels = datapoint\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'test/num_ended_sessions:0' shape=() dtype=int64, numpy=0>\n",
      "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=2>\n",
      "<tf.Variable 'test/num_ended_sessions:0' shape=() dtype=int64, numpy=0>\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('test', tf.AUTO_REUSE):\n",
    "    a = tf.get_variable(\n",
    "        'num_ended_sessions',\n",
    "        shape=(),\n",
    "        initializer=tf.zeros_initializer(),\n",
    "        trainable=False,\n",
    "        dtype=tf.int64)\n",
    "    \n",
    "    print(a)\n",
    "    \n",
    "    a = tf.assign(\n",
    "        a,\n",
    "        tf.add(tf.reduce_sum(features['SessionChanged']),a))\n",
    "    \n",
    "    print(a)\n",
    "    \n",
    "    a = tf.get_variable(\n",
    "        'num_ended_sessions',\n",
    "        shape=(),\n",
    "        initializer=tf.zeros_initializer(),\n",
    "        trainable=False,\n",
    "        dtype=tf.int64)\n",
    "    \n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = features['UserId'].shape[0]\n",
    "\n",
    "num_ended_sessions = tf.get_variable(\n",
    "    'num_ended_sessions',\n",
    "    shape=(),\n",
    "    initializer=tf.zeros_initializer(),\n",
    "    trainable=False,\n",
    "    dtype=tf.int64)\n",
    "\n",
    "num_ended_users = tf.get_variable(\n",
    "    'num_ended_users',\n",
    "    shape=(),\n",
    "    initializer=tf.zeros_initializer(),\n",
    "    trainable=False,\n",
    "    dtype=tf.int64)\n",
    "\n",
    "# Hidden states of session_rnn\n",
    "session_hidden_states = tf.get_variable(\n",
    "    'session_hidden_states',\n",
    "    shape=(batch_size, params['session_rnn_units']),\n",
    "    initializer=tf.zeros_initializer(),\n",
    "    trainable=False)\n",
    "\n",
    "# User Embedding, updated by user_rnn\n",
    "user_embeddings = tf.get_variable(\n",
    "    'user_embeddings',\n",
    "    shape=(params['num_users'], params['user_rnn_units']),\n",
    "    initializer=tf.zeros_initializer(),\n",
    "    trainable=False)\n",
    "\n",
    "# Softmax weights to map RNN output to product space\n",
    "softmax_weights = tf.get_variable(\n",
    "    'softmax_weights',\n",
    "    shape=(params['num_products'], params['session_rnn_units']))\n",
    "\n",
    "# Biases for above\n",
    "softmax_biases = tf.get_variable(\n",
    "    'softmax_biases',\n",
    "    shape=(params['num_products'],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rnn = GRU(\n",
    "    # params['user_rnn_layers'],\n",
    "    params['user_rnn_units'],\n",
    "    return_state=True,\n",
    "    implementation=2,\n",
    "    dropout=params['user_dropout'],\n",
    "    kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "    recurrent_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "    name='user_rnn')\n",
    "\n",
    "session_rnn = GRU(\n",
    "    # params['session_rnn_layers'],\n",
    "    params['session_rnn_units'],\n",
    "    return_state=True,\n",
    "    implementation=2,\n",
    "    dropout=params['session_dropout'],\n",
    "    kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "    recurrent_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "    name='session_rnn')\n",
    "\n",
    "# Layer to predict new session initialization\n",
    "user2session_layer = Dense(\n",
    "    params['session_rnn_units'],\n",
    "    input_shape=(params['user_rnn_units'],),\n",
    "    activation='tanh',\n",
    "    name='user2session_layer')\n",
    "\n",
    "# Dropout layer for session initialization\n",
    "user2session_dropout = Dropout(params['init_dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Update stats\n",
    "num_ended_sessions = tf.add(\n",
    "    tf.reduce_sum(features['SessionChanged']),\n",
    "    num_ended_sessions)\n",
    "\n",
    "num_ended_users = tf.add(\n",
    "    tf.reduce_sum(features['UserChanged']),\n",
    "    num_ended_users)\n",
    "\n",
    "print(num_ended_sessions)\n",
    "print(num_ended_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'num_ended_sessions:0' shape=() dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_variable(\n",
    "    'num_ended_sessions',\n",
    "    shape=(),\n",
    "    initializer=tf.zeros_initializer(),\n",
    "    trainable=False,\n",
    "    dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5 9], shape=(2,), dtype=int64)\n",
      "(2, 25)\n"
     ]
    }
   ],
   "source": [
    "# Get session hidden states to update\n",
    "indices_to_update = tf.squeeze(\n",
    "    tf.where(\n",
    "        tf.cast(features['SessionChanged'], tf.bool),\n",
    "        name='get_indices_to_update'\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "session_states_to_update = tf.gather(\n",
    "    session_hidden_states,\n",
    "    indices_to_update,\n",
    "    name='get_session_states_to_update'\n",
    ")\n",
    "\n",
    "print(indices_to_update)\n",
    "print(session_states_to_update.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 482 1389], shape=(2,), dtype=int64)\n",
      "(2, 50)\n"
     ]
    }
   ],
   "source": [
    "# Get user embeddings to update\n",
    "user_embedding_ids_to_update = tf.gather(\n",
    "    features['UserEmbeddingId'],\n",
    "    indices_to_update\n",
    ")\n",
    "\n",
    "user_embeddings_to_update = tf.nn.embedding_lookup(\n",
    "    user_embeddings,\n",
    "    user_embedding_ids_to_update\n",
    ")\n",
    "\n",
    "print(user_embedding_ids_to_update)\n",
    "print(user_embeddings_to_update.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 25)\n",
      "(2, 50)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]], shape=(2, 25), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Compute new user representation for all users in current batch\n",
    "new_session_hidden_states_seed, new_user_embeddings = user_rnn.apply(\n",
    "    tf.expand_dims(session_states_to_update, 1),\n",
    "    initial_state=user_embeddings_to_update)\n",
    "\n",
    "# Predict new session initialization for next session\n",
    "new_session_hidden_states = user2session_layer.apply(\n",
    "    new_session_hidden_states_seed)\n",
    "\n",
    "new_session_hidden_states = user2session_dropout.apply(\n",
    "    new_session_hidden_states)\n",
    "\n",
    "print(new_session_hidden_states.shape)\n",
    "print(new_user_embeddings.shape)\n",
    "print(new_session_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 25)\n"
     ]
    }
   ],
   "source": [
    "scattered_new_states = tf.scatter_nd(\n",
    "        tf.cast(tf.expand_dims(indices_to_update, axis=1), tf.int32),\n",
    "        new_session_hidden_states,\n",
    "        tf.shape(session_hidden_states)\n",
    "    )\n",
    "print(scattered_new_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Session Hidden States to 0 when a user has ended\n",
    "session_hidden_states = tf.where(\n",
    "    tf.cast(features['UserChanged'], tf.bool),\n",
    "    tf.zeros(tf.shape(session_hidden_states)),\n",
    "    session_hidden_states,\n",
    "    name='reset_session_hidden_states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int64)\n",
      "tf.Tensor([0 2 3 4 5 7 8 9], shape=(8,), dtype=int64)\n",
      "tf.Tensor([0 2 3 4 5 7 8 9], shape=(8,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Compute mask for missing users\n",
    "existing_user_indices = tf.squeeze(tf.where(tf.not_equal(features['UserId'], -1)))\n",
    "\n",
    "print(existing_user_indices)\n",
    "\n",
    "# Compute mask for ending sessions\n",
    "contiuing_session_indices = tf.squeeze(tf.where(\n",
    "        tf.logical_not(\n",
    "            tf.cast(features['LastSessionEvent'], tf.bool))))\n",
    "\n",
    "print(contiuing_session_indices)\n",
    "\n",
    "# Compute relevant indices\n",
    "relevant_indices = tf.squeeze(\n",
    "    tf.sparse.to_dense(\n",
    "        tf.sets.intersection(\n",
    "            existing_user_indices[None, :],\n",
    "            contiuing_session_indices[None, :]\n",
    "        )\n",
    "    ),\n",
    "    axis=0)\n",
    "\n",
    "print(relevant_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute new user representation for all users in current batch\n",
    "new_session_hidden_states_seed, new_user_hidden_states = user_rnn.apply(\n",
    "    tf.expand_dims(session_hidden_states, 1),\n",
    "    initial_state=user_hidden_states)\n",
    "\n",
    "# Predict new session initialization for next session\n",
    "new_session_hidden_states = user2session_layer.apply(\n",
    "    new_session_hidden_states_seed)\n",
    "\n",
    "new_session_hidden_states = user2session_dropout.apply(\n",
    "    new_session_hidden_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select new session initialization for new sessions\n",
    "session_hidden_states = tf.where(\n",
    "    ended_sessions_mask,\n",
    "    new_session_hidden_states,\n",
    "    session_hidden_states,\n",
    "    name='initialize_new_sessions')\n",
    "\n",
    "# Update user hidden states where the session ended\n",
    "user_hidden_states = tf.where(\n",
    "    ended_sessions_mask,\n",
    "    new_user_hidden_states,\n",
    "    user_hidden_states,\n",
    "    name='update_user_representation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute new mask for ended sessions\n",
    "ended_sessions_mask = tf.cast(\n",
    "    tf.where(\n",
    "        tf.equal(features['ProductId'], -1),\n",
    "        tf.ones(tf.shape(ended_sessions_mask)),\n",
    "        tf.zeros(tf.shape(ended_sessions_mask)),\n",
    "        name='compute_ended_sessions'),\n",
    "    tf.bool)\n",
    "\n",
    "# Compute new mask for ending sessions\n",
    "ending_sessions_mask = tf.cast(\n",
    "    tf.where(\n",
    "        tf.equal(labels['ProductId'], -1),\n",
    "        tf.ones(tf.shape(ending_sessions_mask)),\n",
    "        tf.zeros(tf.shape(ending_sessions_mask)),\n",
    "        name='compute_ending_sessions'),\n",
    "    tf.bool)\n",
    "\n",
    "# Compute new mask for ended users\n",
    "ended_users_mask = tf.cast(\n",
    "    tf.where(\n",
    "        tf.equal(features['UserId'], -1),\n",
    "        tf.ones(tf.shape(ended_users_mask)),\n",
    "        tf.zeros(tf.shape(ended_users_mask)),\n",
    "        name='compute_ended_users'),\n",
    "    tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant sessions have not ended and do not end in the next step\n",
    "relevant_sessions_mask = tf.logical_not(\n",
    "    tf.logical_or(\n",
    "        ended_sessions_mask,\n",
    "        ending_sessions_mask))\n",
    "\n",
    "# Get one-hot encoding of products\n",
    "relevant_one_hots = tf.map_fn(\n",
    "    lambda x: tf.cond(\n",
    "        x[1],\n",
    "        lambda: tf.one_hot(x[0], params['num_products']),\n",
    "        lambda: tf.zeros(params['num_products'])\n",
    "    ),\n",
    "    [\n",
    "        features['EmbeddingId'],\n",
    "        relevant_sessions_mask\n",
    "    ],\n",
    "    dtype=tf.float32,\n",
    "    name='get_relevant_one_hots')\n",
    "\n",
    "# Get session hidden states for relevant sessions\n",
    "relevant_hidden_states = tf.where(\n",
    "    relevant_sessions_mask,\n",
    "    session_hidden_states,\n",
    "    tf.zeros(tf.shape(session_hidden_states)),\n",
    "    name='get_relevant_session_hidden_states'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(10), Dimension(2600000)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_one_hots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Session RNN -> get new hidden states and predictions\n",
    "predictions, new_session_hidden_states = session_rnn.apply(\n",
    "    tf.expand_dims(relevant_one_hots, 1),\n",
    "    initial_state=relevant_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out irrelevant predictions\n",
    "predictions = tf.boolean_mask(\n",
    "    predictions,\n",
    "    relevant_sessions_mask,\n",
    "    name='filter_irrelevant_predictions')\n",
    "\n",
    "# Update session hidden states for relevant sessions\n",
    "session_hidden_states = tf.where(\n",
    "    relevant_sessions_mask,\n",
    "    new_session_hidden_states,\n",
    "    session_hidden_states,\n",
    "    name='update_relevant_session_hidden_states')\n",
    "\n",
    "# Extract relevant labels\n",
    "relevant_labels = tf.boolean_mask(\n",
    "    labels['EmbeddingId'],\n",
    "    relevant_sessions_mask,\n",
    "    name='filter_irrelevant_labels')\n",
    "\n",
    "# Compute logits for product predictions\n",
    "logits = tf.matmul(\n",
    "    predictions,\n",
    "    softmax_weights,\n",
    "    transpose_b=True) + softmax_biases\n",
    "\n",
    "# Apply softmax activation\n",
    "softmax_predictions = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1184, shape=(2,), dtype=int32, numpy=array([     10, 2600000], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(softmax_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Hitrate\n",
    "\n",
    "in_top_k = tf.nn.in_top_k(softmax_predictions, relevant_labels, 5)\n",
    "hitrate = tf.divide(\n",
    "    tf.reduce_sum(tf.cast(in_top_k, tf.int64)),\n",
    "    tf.shape(labels)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Loss Function\n",
    "\n",
    "negative_samples_weights = tf.nn.embedding_lookup(softmax_weights, relevant_labels)\n",
    "negative_samples_biases = tf.nn.embedding_lookup(softmax_biases, relevant_labels)\n",
    "\n",
    "logits = tf.matmul(predicted_embeddings, negative_samples_weights, transpose_b=True) + negative_samples_biases\n",
    "yhat = tf.nn.softmax(logits) # for each of the examples in the batch we select the remainder of the minibatch as negative examples\n",
    "\n",
    "# TOP 1 Loss function\n",
    "yhatT = tf.transpose(yhat)\n",
    "term1 = tf.reduce_mean(tf.nn.sigmoid(-tf.diag_part(yhat)+yhatT)+tf.nn.sigmoid(yhatT**2), axis=0)\n",
    "term2 = tf.nn.sigmoid(tf.diag_part(yhat)**2) / batch_size.value\n",
    "loss = tf.reduce_mean(term1 - term2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2867, shape=(), dtype=float32, numpy=0.9640579>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "`loss` passed to Optimizer.compute_gradients should be a function when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-c9a5cbb247ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/code-JIyQgSPM/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/code-JIyQgSPM/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m       raise RuntimeError(\n\u001b[0;32m--> 481\u001b[0;31m           \u001b[0;34m\"`loss` passed to Optimizer.compute_gradients should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m           \"be a function when eager execution is enabled.\")\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `loss` passed to Optimizer.compute_gradients should be a function when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op = optimizer.minimize(loss, global_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=639, shape=(10, 25), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_hidden_states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
