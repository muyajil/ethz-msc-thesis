\chapter{Experiments}
For each of the model variants evaluate the experiments offline and online.
\section{Offline}
\subsection{Experiment Setup}\label{sec:exp_setup}
\begin{itemize}
    \item Describe the last session out split (test and eval)
    \item Describe how we train the model and how we evaluate it
\end{itemize}
\subsection{Measurements}
\begin{itemize}
    \item Here we want to confirm a few things: user rnn helps, embeddings helps, profforcing helps
    \item The evaluation set is always the same
    \item Show the relevant KPIs (described in the chapter before)
\end{itemize}

\section{Online/Production Experiment Setup}
\subsection{Experiment Setup}
\begin{itemize}
    \item Describe the online shop
    \item Where do we have recommendations, general description
    \item Explain SOFI
    \item Where do we put our recommendation system? Against what does it compete?
    \item Also describe the testing engine
\end{itemize}
\subsection{Measurements}
\begin{itemize}
    \item First measure for each variant what the performance is (an ABCD test so to say, split customers maybe, there should be enough)
    \item Then explain the performance of Simple models
    \item After that the performance of a black box, specifically Google's AutoML
    \item Show results for AutoML, Often Bought Together and our system in the different variants
    \item Show the relevant KPIs
\end{itemize}