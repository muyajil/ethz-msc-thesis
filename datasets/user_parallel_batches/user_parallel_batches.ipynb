{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Dataset\n",
    "\n",
    "- This dataset is used to implement the baseline from the paper \"Personalizing Session based Recommendations with Hierarchical RNNs\" -> resources/papers/personalizing_session_based_rec.pdf\n",
    "- This dataset is generated from the OnlineShopTrafficTracking Table in BigQuery\n",
    "- Clean out bots using: https://github.com/monperrus/crawler-user-agents/blob/master/crawler-user-agents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "TESTMODE = False\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(action='ignore', category=ResourceWarning)\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import time\n",
    "from io import StringIO\n",
    "from dg_ml_core.datastores import gcs_utils\n",
    "from dg_ml_core.file import get_file_handle, get_paths_with_prefix, save_to_file, file_exists, copy_file\n",
    "from dg_ml_core.collections import dict_ops\n",
    "from dg_ml_core.datastores import gcs_utils\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import pprint\n",
    "from statistics import mean, median, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bots_list():\n",
    "    url = 'https://raw.githubusercontent.com/monperrus/crawler-user-agents/master/crawler-user-agents.json'\n",
    "    response = requests.get(url)\n",
    "    data = json.loads(response.content)\n",
    "    all_instances = [item for sublist in map(lambda x: x['instances'], data) for item in sublist]\n",
    "    return all_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Query in BQ\n",
    "\n",
    "- Here we extract the relevant features out of the large collection of visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query \n",
      "SELECT (SELECT Value FROM UNNEST(ActionParameters) WHERE Key = 'id') as ProductId, LastLoggedInUserId, UserId, SessionId, UserAgent, Timestamp\n",
      "FROM `dg-prod-personalization.PersonalizationDataV2.OnlineShopTrafficTracking` \n",
      "WHERE LOWER(ControllerName) = 'product' AND LOWER(ActionName) = 'show' AND UserId > 0\n",
      " AND _PARTITIONTIME < TIMESTAMP(\"2019-02-11\"). \n",
      "You have 5 seconds to cancel...\n",
      "Running Job baseline_dataset_query_df2b2811-b0bd-440f-9371-988a33ccd80e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x7fad64ce9da0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution done\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT (SELECT Value FROM UNNEST(ActionParameters) WHERE Key = 'id') as ProductId, LastLoggedInUserId, UserId, SessionId, UserAgent, Timestamp\n",
    "FROM `dg-prod-personalization.PersonalizationDataV2.OnlineShopTrafficTracking` \n",
    "WHERE LOWER(ControllerName) = 'product' AND LOWER(ActionName) = 'show' AND UserId > 0\n",
    "\"\"\"\n",
    "\n",
    "if TESTMODE:\n",
    "    query += ' AND _PARTITIONTIME = TIMESTAMP(\"2019-02-11\")'\n",
    "else:\n",
    "    query += ' AND _PARTITIONTIME < TIMESTAMP(\"2019-02-11\")'\n",
    "    \n",
    "print('Executing query {}. \\nYou have 5 seconds to cancel...'.format(query))\n",
    "time.sleep(5)\n",
    "\n",
    "client = bigquery.Client()\n",
    "dataset_ref = client.dataset('MAMuy', project='machinelearning-prod')\n",
    "table_ref = dataset_ref.table('baseline_dataset')\n",
    "\n",
    "job_config = bigquery.job.QueryJobConfig(\n",
    "    allow_large_results=True, \n",
    "    destination=table_ref,\n",
    "    write_disposition=bigquery.job.WriteDisposition.WRITE_TRUNCATE)\n",
    "\n",
    "query_job = client.query(query, job_config=job_config, job_id_prefix='baseline_dataset_query_', location='EU')\n",
    "print('Running Job {}'.format(query_job.job_id))\n",
    "query_job.result()\n",
    "\n",
    "print('Query execution done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract to GCS\n",
    "\n",
    "- Extract the table containing the relevant features to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Job baseline_dataset_extract_42af8c64-687a-4897-a333-1ec49119f06c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.job.ExtractJob at 0x7fad64d8c630>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction done\n"
     ]
    }
   ],
   "source": [
    "destination_uri = 'gs://ma-muy/baseline_dataset/raw/*.csv'\n",
    "\n",
    "client = bigquery.Client()\n",
    "dataset_ref = client.dataset('MAMuy', project='machinelearning-prod')\n",
    "table_ref = dataset_ref.table('baseline_dataset')\n",
    "\n",
    "extract_job = client.extract_table(\n",
    "    table_ref,\n",
    "    destination_uri,\n",
    "    location='EU',\n",
    "    job_id_prefix='baseline_dataset_extract_')\n",
    "\n",
    "print('Running Job {}'.format(extract_job.job_id))\n",
    "extract_job.result()\n",
    "print('Extraction done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data\n",
    "\n",
    "- Here we clean the data.\n",
    "- Specifically there are two steps:\n",
    "  - Clean out bot visits\n",
    "  - Merge LastLoggedInUserId and UserId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000007.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000007.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000007.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000008.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000008.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000008.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000009.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000009.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000009.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000010.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000010.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000010.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000011.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000011.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000011.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000012.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000012.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000012.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000013.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000013.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000013.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000014.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000014.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000014.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000015.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000015.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000015.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000016.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000016.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000016.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000017.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000017.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000017.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000018.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000018.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000018.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000019.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000019.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000019.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000020.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000020.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000020.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000021.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000021.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000021.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000022.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000022.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000022.csv\n",
      "Downloading gs://ma-muy/baseline_dataset/raw/000000000023.csv\n",
      "Processing gs://ma-muy/baseline_dataset/raw/000000000023.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/clean/000000000023.csv\n"
     ]
    }
   ],
   "source": [
    "def clean_dataset(source, target):\n",
    "    col_types = {\"ProductId\": 'Float64', \n",
    "             \"UserId\": 'Float64', \n",
    "             \"UserAgent\": str, \n",
    "             \"LastLoggedInUserId\": 'Float64', \n",
    "             \"SessionId\": 'Float64', \n",
    "             \"Timestamp\": 'Float64'}\n",
    "    \n",
    "    df = pd.read_csv(source, dtype=col_types).fillna(-1)\n",
    "    bots = get_bots_list()\n",
    "    df = df[~df.UserAgent.isin(bots)]\n",
    "    df = df.dropna(subset=[\"ProductId\"])\n",
    "    \n",
    "    no_user_id_mask = df.UserId == -1\n",
    "    df.loc[no_user_id_mask, 'UserId'] = df.loc[no_user_id_mask, 'LastLoggedInUserId']\n",
    "    \n",
    "    df.to_csv(target, index=False, columns=['UserId', 'ProductId', 'SessionId', 'Timestamp'])\n",
    "\n",
    "    return target\n",
    "\n",
    "##################################################################\n",
    "\n",
    "if TESTMODE:\n",
    "    print('Processing example.csv')\n",
    "    df = clean_dataset('example.csv', 'example_clean.csv')\n",
    "    \n",
    "else:\n",
    "    raw_data_prefix = 'gs://ma-muy/baseline_dataset/raw/'\n",
    "    cleaned_data_prefix = 'gs://ma-muy/baseline_dataset/clean/'\n",
    "    \n",
    "    client = storage.Client.from_service_account_json('../../service-account.json')\n",
    "    \n",
    "    raw_paths = get_paths_with_prefix(raw_data_prefix)\n",
    "    \n",
    "    for raw_path in raw_paths:\n",
    "        clean_path = cleaned_data_prefix + gcs_utils.get_file_name(raw_path)\n",
    "\n",
    "        print('Processing {}'.format(raw_path))\n",
    "        source = get_file_handle(raw_path, gcs_client=client)\n",
    "        target = StringIO()\n",
    "        \n",
    "        target = clean_dataset(source, target)\n",
    "        \n",
    "        save_to_file(clean_path, target.getvalue(), gcs_client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Sessions\n",
    "\n",
    "- In this step we will merge all the single visit events into sessions\n",
    "- Further we merge all sessions to the specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000000.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000000.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000000.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000001.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000001.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000001.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000002.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000002.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000002.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000003.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000003.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000003.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000004.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000004.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000004.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000005.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000005.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000005.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000006.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000006.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000006.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000007.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000007.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000007.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000008.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000008.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000008.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000009.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000009.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000009.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000010.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000010.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000010.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000011.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000011.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000011.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000012.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000012.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000012.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000013.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000013.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000013.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000014.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000014.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000014.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000015.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000015.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000015.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000016.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000016.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000016.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000017.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000017.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000017.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000018.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000018.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000018.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000019.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000019.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000019.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000020.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000020.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000020.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000021.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000021.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000021.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000022.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000022.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000022.json\n",
      "Downloading gs://ma-muy/baseline_dataset/clean/000000000023.csv\n",
      "Processing gs://ma-muy/baseline_dataset/clean/000000000023.csv\n",
      "Uploading gs://ma-muy/baseline_dataset/merged/000000000023.json\n",
      "Number of unique Products in dataset: 1258092\n",
      "Number of unique Users in dataset: 1211522\n",
      "Number of unique Sessions in dataset: 18479343\n"
     ]
    }
   ],
   "source": [
    "def merge_sessions(reader):\n",
    "    sessions_by_user = dict()\n",
    "    for row in reader:\n",
    "        user_id = str(int(float(row['UserId'])))\n",
    "        session_id = str(int(float(row['SessionId'])))\n",
    "        product_id = int(float(row['ProductId']))\n",
    "        timestamp = int(float(row['Timestamp']))\n",
    "        \n",
    "        if user_id not in sessions_by_user:\n",
    "            sessions_by_user[user_id] = dict()\n",
    "        \n",
    "        if session_id not in sessions_by_user[user_id]:\n",
    "            sessions_by_user[user_id][session_id] = dict()\n",
    "            sessions_by_user[user_id][session_id]['Events'] = []\n",
    "        \n",
    "        sessions_by_user[user_id][session_id]['Events'].append(\n",
    "            {\n",
    "                \"ProductId\": product_id,\n",
    "                \"Timestamp\": timestamp\n",
    "            })\n",
    "        \n",
    "        first_event_ts = min(map(lambda x: int(x['Timestamp']), sessions_by_user[user_id][session_id]['Events']))\n",
    "        sessions_by_user[user_id][session_id]['StartTime'] = first_event_ts\n",
    "    return sessions_by_user, unique_products, unique_users, unique_sessions\n",
    "\n",
    "##################################################################\n",
    "\n",
    "if TESTMODE:\n",
    "    reader = csv.DictReader(open('example_clean.csv'))\n",
    "    \n",
    "    unique_products = set()\n",
    "    unique_users = set()\n",
    "    unique_sessions = set()\n",
    "    \n",
    "    sessions_by_user = merge_sessions(reader)\n",
    "    \n",
    "    dict_ops.save_dict('example_merged.json', sessions_by_user)\n",
    "\n",
    "else:\n",
    "    cleaned_data_prefix = 'gs://ma-muy/baseline_dataset/clean/'\n",
    "    merged_data_prefix = 'gs://ma-muy/baseline_dataset/merged/'\n",
    "    \n",
    "    client = storage.Client.from_service_account_json('../../service-account.json')\n",
    "    \n",
    "    clean_paths = get_paths_with_prefix(cleaned_data_prefix)\n",
    "    for clean_path in clean_paths:\n",
    "        merged_path = (merged_data_prefix + gcs_utils.get_file_name(clean_path)).replace('csv', 'json')\n",
    "        \n",
    "        print('Processing {}'.format(clean_path))\n",
    "        source = get_file_handle(clean_path, gcs_client=client)\n",
    "        reader = csv.DictReader(source)\n",
    "        \n",
    "        sessions_by_user = merge_sessions(reader)\n",
    "        \n",
    "        dict_ops.save_dict(merged_path, sessions_by_user, gcs_client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge shards\n",
    "\n",
    "- As of now we have several shards, containing the sessions aggregated to the user level.\n",
    "- The merging of the shards is the most time consuming part of the data generation process. \n",
    "- We need to merge all sessions of a specific user into one datastructure.\n",
    "- In production we will be dealing with daily shards, which makes the generation of the dataset easier\n",
    "- However in this case we will be dealing with full exports, therefore we cannot assume that a shard is from one day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gs://ma-muy/baseline_dataset/merged/000000000022.json\n",
      "Processing gs://ma-muy/baseline_dataset/merged/000000000022.json\n",
      "==================================================================================================== Finished!\n",
      "Downloading gs://ma-muy/baseline_dataset/merged/000000000023.json\n",
      "Processing gs://ma-muy/baseline_dataset/merged/000000000023.json\n",
      "==================================================================================================== Finished!\n",
      "Uploading temp_sessions_by_user/67.json to gs://ma-muy/baseline_dataset/sessions_by_user/67.json\n",
      "Uploading temp_sessions_by_user/44.json to gs://ma-muy/baseline_dataset/sessions_by_user/44.json\n",
      "Uploading temp_sessions_by_user/8.json to gs://ma-muy/baseline_dataset/sessions_by_user/8.json\n",
      "Uploading temp_sessions_by_user/97.json to gs://ma-muy/baseline_dataset/sessions_by_user/97.json\n",
      "Uploading temp_sessions_by_user/34.json to gs://ma-muy/baseline_dataset/sessions_by_user/34.json\n",
      "Uploading temp_sessions_by_user/48.json to gs://ma-muy/baseline_dataset/sessions_by_user/48.json\n",
      "Uploading temp_sessions_by_user/63.json to gs://ma-muy/baseline_dataset/sessions_by_user/63.json\n",
      "Uploading temp_sessions_by_user/32.json to gs://ma-muy/baseline_dataset/sessions_by_user/32.json\n",
      "Uploading temp_sessions_by_user/95.json to gs://ma-muy/baseline_dataset/sessions_by_user/95.json\n",
      "Uploading temp_sessions_by_user/54.json to gs://ma-muy/baseline_dataset/sessions_by_user/54.json\n",
      "Uploading temp_sessions_by_user/43.json to gs://ma-muy/baseline_dataset/sessions_by_user/43.json\n",
      "Uploading temp_sessions_by_user/11.json to gs://ma-muy/baseline_dataset/sessions_by_user/11.json\n",
      "Uploading temp_sessions_by_user/5.json to gs://ma-muy/baseline_dataset/sessions_by_user/5.json\n",
      "Uploading temp_sessions_by_user/27.json to gs://ma-muy/baseline_dataset/sessions_by_user/27.json\n",
      "Uploading temp_sessions_by_user/76.json to gs://ma-muy/baseline_dataset/sessions_by_user/76.json\n",
      "Uploading temp_sessions_by_user/96.json to gs://ma-muy/baseline_dataset/sessions_by_user/96.json\n",
      "Uploading temp_sessions_by_user/75.json to gs://ma-muy/baseline_dataset/sessions_by_user/75.json\n",
      "Uploading temp_sessions_by_user/84.json to gs://ma-muy/baseline_dataset/sessions_by_user/84.json\n",
      "Uploading temp_sessions_by_user/15.json to gs://ma-muy/baseline_dataset/sessions_by_user/15.json\n",
      "Uploading temp_sessions_by_user/23.json to gs://ma-muy/baseline_dataset/sessions_by_user/23.json\n",
      "Uploading temp_sessions_by_user/99.json to gs://ma-muy/baseline_dataset/sessions_by_user/99.json\n",
      "Uploading temp_sessions_by_user/6.json to gs://ma-muy/baseline_dataset/sessions_by_user/6.json\n",
      "Uploading temp_sessions_by_user/72.json to gs://ma-muy/baseline_dataset/sessions_by_user/72.json\n",
      "Uploading temp_sessions_by_user/90.json to gs://ma-muy/baseline_dataset/sessions_by_user/90.json\n",
      "Uploading temp_sessions_by_user/94.json to gs://ma-muy/baseline_dataset/sessions_by_user/94.json\n",
      "Uploading temp_sessions_by_user/30.json to gs://ma-muy/baseline_dataset/sessions_by_user/30.json\n",
      "Uploading temp_sessions_by_user/88.json to gs://ma-muy/baseline_dataset/sessions_by_user/88.json\n",
      "Uploading temp_sessions_by_user/21.json to gs://ma-muy/baseline_dataset/sessions_by_user/21.json\n",
      "Uploading temp_sessions_by_user/45.json to gs://ma-muy/baseline_dataset/sessions_by_user/45.json\n",
      "Uploading temp_sessions_by_user/36.json to gs://ma-muy/baseline_dataset/sessions_by_user/36.json\n",
      "Uploading temp_sessions_by_user/59.json to gs://ma-muy/baseline_dataset/sessions_by_user/59.json\n",
      "Uploading temp_sessions_by_user/50.json to gs://ma-muy/baseline_dataset/sessions_by_user/50.json\n",
      "Uploading temp_sessions_by_user/60.json to gs://ma-muy/baseline_dataset/sessions_by_user/60.json\n",
      "Uploading temp_sessions_by_user/56.json to gs://ma-muy/baseline_dataset/sessions_by_user/56.json\n",
      "Uploading temp_sessions_by_user/7.json to gs://ma-muy/baseline_dataset/sessions_by_user/7.json\n",
      "Uploading temp_sessions_by_user/79.json to gs://ma-muy/baseline_dataset/sessions_by_user/79.json\n",
      "Uploading temp_sessions_by_user/68.json to gs://ma-muy/baseline_dataset/sessions_by_user/68.json\n",
      "Uploading temp_sessions_by_user/87.json to gs://ma-muy/baseline_dataset/sessions_by_user/87.json\n",
      "Uploading temp_sessions_by_user/61.json to gs://ma-muy/baseline_dataset/sessions_by_user/61.json\n",
      "Uploading temp_sessions_by_user/78.json to gs://ma-muy/baseline_dataset/sessions_by_user/78.json\n",
      "Uploading temp_sessions_by_user/16.json to gs://ma-muy/baseline_dataset/sessions_by_user/16.json\n",
      "Uploading temp_sessions_by_user/41.json to gs://ma-muy/baseline_dataset/sessions_by_user/41.json\n",
      "Uploading temp_sessions_by_user/91.json to gs://ma-muy/baseline_dataset/sessions_by_user/91.json\n",
      "Uploading temp_sessions_by_user/13.json to gs://ma-muy/baseline_dataset/sessions_by_user/13.json\n",
      "Uploading temp_sessions_by_user/51.json to gs://ma-muy/baseline_dataset/sessions_by_user/51.json\n",
      "Uploading temp_sessions_by_user/9.json to gs://ma-muy/baseline_dataset/sessions_by_user/9.json\n",
      "Uploading temp_sessions_by_user/2.json to gs://ma-muy/baseline_dataset/sessions_by_user/2.json\n",
      "Uploading temp_sessions_by_user/10.json to gs://ma-muy/baseline_dataset/sessions_by_user/10.json\n",
      "Uploading temp_sessions_by_user/33.json to gs://ma-muy/baseline_dataset/sessions_by_user/33.json\n",
      "Uploading temp_sessions_by_user/93.json to gs://ma-muy/baseline_dataset/sessions_by_user/93.json\n",
      "Uploading temp_sessions_by_user/85.json to gs://ma-muy/baseline_dataset/sessions_by_user/85.json\n",
      "Uploading temp_sessions_by_user/86.json to gs://ma-muy/baseline_dataset/sessions_by_user/86.json\n",
      "Uploading temp_sessions_by_user/92.json to gs://ma-muy/baseline_dataset/sessions_by_user/92.json\n",
      "Uploading temp_sessions_by_user/89.json to gs://ma-muy/baseline_dataset/sessions_by_user/89.json\n",
      "Uploading temp_sessions_by_user/39.json to gs://ma-muy/baseline_dataset/sessions_by_user/39.json\n",
      "Uploading temp_sessions_by_user/49.json to gs://ma-muy/baseline_dataset/sessions_by_user/49.json\n",
      "Uploading temp_sessions_by_user/62.json to gs://ma-muy/baseline_dataset/sessions_by_user/62.json\n",
      "Uploading temp_sessions_by_user/28.json to gs://ma-muy/baseline_dataset/sessions_by_user/28.json\n",
      "Uploading temp_sessions_by_user/64.json to gs://ma-muy/baseline_dataset/sessions_by_user/64.json\n",
      "Uploading temp_sessions_by_user/58.json to gs://ma-muy/baseline_dataset/sessions_by_user/58.json\n",
      "Uploading temp_sessions_by_user/74.json to gs://ma-muy/baseline_dataset/sessions_by_user/74.json\n",
      "Uploading temp_sessions_by_user/57.json to gs://ma-muy/baseline_dataset/sessions_by_user/57.json\n",
      "Uploading temp_sessions_by_user/4.json to gs://ma-muy/baseline_dataset/sessions_by_user/4.json\n",
      "Uploading temp_sessions_by_user/77.json to gs://ma-muy/baseline_dataset/sessions_by_user/77.json\n",
      "Uploading temp_sessions_by_user/20.json to gs://ma-muy/baseline_dataset/sessions_by_user/20.json\n",
      "Uploading temp_sessions_by_user/98.json to gs://ma-muy/baseline_dataset/sessions_by_user/98.json\n",
      "Uploading temp_sessions_by_user/80.json to gs://ma-muy/baseline_dataset/sessions_by_user/80.json\n",
      "Uploading temp_sessions_by_user/24.json to gs://ma-muy/baseline_dataset/sessions_by_user/24.json\n",
      "Uploading temp_sessions_by_user/14.json to gs://ma-muy/baseline_dataset/sessions_by_user/14.json\n",
      "Uploading temp_sessions_by_user/52.json to gs://ma-muy/baseline_dataset/sessions_by_user/52.json\n",
      "Uploading temp_sessions_by_user/82.json to gs://ma-muy/baseline_dataset/sessions_by_user/82.json\n",
      "Uploading temp_sessions_by_user/37.json to gs://ma-muy/baseline_dataset/sessions_by_user/37.json\n",
      "Uploading temp_sessions_by_user/12.json to gs://ma-muy/baseline_dataset/sessions_by_user/12.json\n",
      "Uploading temp_sessions_by_user/53.json to gs://ma-muy/baseline_dataset/sessions_by_user/53.json\n",
      "Uploading temp_sessions_by_user/19.json to gs://ma-muy/baseline_dataset/sessions_by_user/19.json\n",
      "Uploading temp_sessions_by_user/22.json to gs://ma-muy/baseline_dataset/sessions_by_user/22.json\n",
      "Uploading temp_sessions_by_user/55.json to gs://ma-muy/baseline_dataset/sessions_by_user/55.json\n",
      "Uploading temp_sessions_by_user/0.json to gs://ma-muy/baseline_dataset/sessions_by_user/0.json\n",
      "Uploading temp_sessions_by_user/3.json to gs://ma-muy/baseline_dataset/sessions_by_user/3.json\n",
      "Uploading temp_sessions_by_user/46.json to gs://ma-muy/baseline_dataset/sessions_by_user/46.json\n",
      "Uploading temp_sessions_by_user/17.json to gs://ma-muy/baseline_dataset/sessions_by_user/17.json\n",
      "Uploading temp_sessions_by_user/1.json to gs://ma-muy/baseline_dataset/sessions_by_user/1.json\n",
      "Uploading temp_sessions_by_user/29.json to gs://ma-muy/baseline_dataset/sessions_by_user/29.json\n",
      "Uploading temp_sessions_by_user/70.json to gs://ma-muy/baseline_dataset/sessions_by_user/70.json\n",
      "Uploading temp_sessions_by_user/69.json to gs://ma-muy/baseline_dataset/sessions_by_user/69.json\n",
      "Uploading temp_sessions_by_user/25.json to gs://ma-muy/baseline_dataset/sessions_by_user/25.json\n",
      "Uploading temp_sessions_by_user/65.json to gs://ma-muy/baseline_dataset/sessions_by_user/65.json\n",
      "Uploading temp_sessions_by_user/18.json to gs://ma-muy/baseline_dataset/sessions_by_user/18.json\n",
      "Uploading temp_sessions_by_user/71.json to gs://ma-muy/baseline_dataset/sessions_by_user/71.json\n",
      "Uploading temp_sessions_by_user/40.json to gs://ma-muy/baseline_dataset/sessions_by_user/40.json\n",
      "Uploading temp_sessions_by_user/66.json to gs://ma-muy/baseline_dataset/sessions_by_user/66.json\n",
      "Uploading temp_sessions_by_user/81.json to gs://ma-muy/baseline_dataset/sessions_by_user/81.json\n",
      "Uploading temp_sessions_by_user/42.json to gs://ma-muy/baseline_dataset/sessions_by_user/42.json\n",
      "Uploading temp_sessions_by_user/47.json to gs://ma-muy/baseline_dataset/sessions_by_user/47.json\n",
      "Uploading temp_sessions_by_user/35.json to gs://ma-muy/baseline_dataset/sessions_by_user/35.json\n",
      "Uploading temp_sessions_by_user/31.json to gs://ma-muy/baseline_dataset/sessions_by_user/31.json\n",
      "Uploading temp_sessions_by_user/26.json to gs://ma-muy/baseline_dataset/sessions_by_user/26.json\n",
      "Uploading temp_sessions_by_user/38.json to gs://ma-muy/baseline_dataset/sessions_by_user/38.json\n",
      "Uploading temp_sessions_by_user/83.json to gs://ma-muy/baseline_dataset/sessions_by_user/83.json\n",
      "Uploading temp_sessions_by_user/73.json to gs://ma-muy/baseline_dataset/sessions_by_user/73.json\n"
     ]
    }
   ],
   "source": [
    "def generate_sessions_by_user(shard, merged_shards_prefix, num_target_files):\n",
    "    \n",
    "    gcs_client = storage.Client.from_service_account_json('../../service-account.json')\n",
    "    \n",
    "    path = ''\n",
    "    new_path = ''\n",
    "    output_dict = dict()\n",
    "    \n",
    "    for i in range(num_target_files):\n",
    "        print('=', end='', flush=True)\n",
    "        relevant_user_ids = list(filter(lambda x: int(x) % num_target_files == i, shard.keys()))\n",
    "        \n",
    "        path = merged_shards_prefix + str(i) + '.json' # Add a datestamp hierarchy\n",
    "        \n",
    "        if file_exists(path):\n",
    "            output_dict = dict_ops.load_dict(path, gcs_client=gcs_client)\n",
    "        else:\n",
    "            output_dict = dict()\n",
    "            \n",
    "        for user_id in relevant_user_ids:\n",
    "            if int(user_id) > 0:\n",
    "                for session_id in shard[user_id]:\n",
    "                    if user_id not in output_dict:\n",
    "                        output_dict[user_id] = dict()\n",
    "\n",
    "                    if session_id not in output_dict[user_id]:\n",
    "                        output_dict[user_id][session_id] = shard[user_id][session_id]\n",
    "\n",
    "                    else:\n",
    "                        merged_events = output_dict[user_id][session_id]['Events'] + shard[user_id][session_id]['Events']\n",
    "                        merged_events_str = map(lambda x: json.dumps(x), merged_events)\n",
    "                        unique_events_str = set(merged_events_str)\n",
    "                        unique_events = list(map(lambda x: json.loads(x), unique_events_str))\n",
    "                        output_dict[user_id][session_id]['Events'] = unique_events\n",
    "                        output_dict[user_id][session_id]['StartTime'] = min(map(lambda x: int(x['Timestamp']), unique_events))\n",
    "\n",
    "        dict_ops.save_dict(path, output_dict, gcs_client=gcs_client)\n",
    "    print(' Finished!')\n",
    "    \n",
    "##################################################################\n",
    "\n",
    "NUM_TARGET_FILES = 100\n",
    "if TESTMODE:\n",
    "    shard = json.load(open('example_merged.json'))\n",
    "    generate_sessions_by_user(shard, 'sessions_by_user/', NUM_TARGET_FILES)\n",
    "else:\n",
    "    merged_data_prefix = 'gs://ma-muy/baseline_dataset/merged/'\n",
    "    sessions_by_user_prefix = 'gs://ma-muy/baseline_dataset/sessions_by_user/'\n",
    "    temp_sessions_by_user_prefix = 'temp_sessions_by_user/'\n",
    "    \n",
    "    client = storage.Client.from_service_account_json('../../service-account.json')\n",
    "    \n",
    "    merged_paths = get_paths_with_prefix(merged_data_prefix)\n",
    "    for merged_path in merged_paths[-2:]:\n",
    "        \n",
    "        print('Processing {}'.format(merged_path))\n",
    "        source = dict_ops.load_dict(merged_path)\n",
    "        \n",
    "        generate_sessions_by_user(source, temp_sessions_by_user_prefix, NUM_TARGET_FILES)\n",
    "    \n",
    "    temp_files = get_paths_with_prefix(temp_sessions_by_user_prefix)\n",
    "    \n",
    "    print('Uploading Files')\n",
    "    \n",
    "    for temp_file in temp_files:\n",
    "        file_name = temp_file.rsplit('/', 1)[1]\n",
    "        if 'ipynb' not in file_name:\n",
    "            target_uri = sessions_by_user_prefix + file_name\n",
    "            copy_file(temp_file, target_uri, gcs_client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data & Collect Statistics\n",
    "\n",
    "- At this point we have the data in a form that is nice for preprocessing.\n",
    "- During preprocessing we can also collect dataset stats\n",
    "- According to the paper there are several steps to preprocess the session data:\n",
    "    - Remove Items with low support (which threshold to use? 10 vs. 20)\n",
    "    - Remove sessions with less than 3 items\n",
    "    - Remove users with less than 5 sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/0.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/1.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/10.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/11.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/12.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/13.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/14.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/15.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/16.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/17.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/18.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/19.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/2.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/20.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/21.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/22.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/23.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/24.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/25.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/26.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/27.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/28.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/29.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/3.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/30.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/31.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/32.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/33.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/34.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/35.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/36.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/37.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/38.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/39.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/4.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/40.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/41.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/42.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/43.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/44.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/45.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/46.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/47.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/48.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/49.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/5.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/50.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/51.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/52.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/53.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/54.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/55.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/56.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/57.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/58.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/59.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/6.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/60.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/61.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/62.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/63.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/64.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/65.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/66.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/67.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/68.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/69.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/7.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/70.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/71.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/72.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/73.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/74.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/75.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/76.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/77.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/78.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/79.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/8.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/80.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/81.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/82.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/83.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/84.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/85.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/86.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/87.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/88.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/89.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/9.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/90.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/91.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/92.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/93.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/94.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/95.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/96.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/97.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/98.json\n",
      "Processing gs://ma-muy/baseline_dataset/sessions_by_user/99.json\n"
     ]
    }
   ],
   "source": [
    "def filter_sessions_and_users(input_dict, \n",
    "                              min_sessions_per_user, \n",
    "                              min_events_per_session, \n",
    "                              events_per_products):\n",
    "    \n",
    "    output_dict = dict()\n",
    "    \n",
    "    for user_id in input_dict:\n",
    "        output_dict[user_id] = dict()\n",
    "        for session_id in input_dict[user_id]:\n",
    "            if len(input_dict[user_id][session_id]['Events']) >= min_events_per_session:\n",
    "                output_dict[user_id][session_id] = input_dict[user_id][session_id]\n",
    "                product_ids = list(map(lambda x: x['ProductId'], output_dict[user_id][session_id]['Events']))\n",
    "                for product_id in product_ids:\n",
    "                    if product_id in events_per_products:\n",
    "                        events_per_products[product_id] += 1\n",
    "                    else:\n",
    "                        events_per_products[product_id] = 1\n",
    "        if len(output_dict[user_id]) < min_sessions_per_user:\n",
    "            _ = output_dict.pop(user_id, None)\n",
    "    \n",
    "    return output_dict, events_per_products\n",
    "\n",
    "##################################################################\n",
    "\n",
    "events_per_product = dict()\n",
    "\n",
    "sessions_by_user_prefix = 'gs://ma-muy/baseline_dataset/sessions_by_user/'\n",
    "    \n",
    "client = storage.Client.from_service_account_json('../../service-account.json')\n",
    "paths = get_paths_with_prefix(sessions_by_user_prefix)\n",
    "\n",
    "min_sessions_per_user = 5\n",
    "min_events_per_session = 3\n",
    "\n",
    "for path in paths:\n",
    "    \n",
    "    print('Processing {}'.format(path))\n",
    "    input_dict = dict_ops.load_dict(path, gcs_client=client)\n",
    "    \n",
    "    output_dict, events_per_product = filter_sessions_and_users(input_dict,\n",
    "                                                            min_sessions_per_user,\n",
    "                                                            min_events_per_session,\n",
    "                                                            events_per_product)\n",
    "    \n",
    "    output_path = path.replace('sessions_by_user', 'filtered_users_and_sessions')\n",
    "    dict_ops.save_dict(output_path, output_dict, gcs_client=client)\n",
    "    \n",
    "dict_ops.save_dict('events_per_product.json', events_per_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Products: 1178536\n",
      "Products with low support: 598689\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/0.json\n",
      "Filtered 9942 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/1.json\n",
      "Filtered 8506 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/10.json\n",
      "Filtered 8792 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/11.json\n",
      "Filtered 9159 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/12.json\n",
      "Filtered 9565 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/13.json\n",
      "Filtered 9126 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/14.json\n",
      "Filtered 10180 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/15.json\n",
      "Filtered 8811 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/16.json\n",
      "Filtered 9309 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/17.json\n",
      "Filtered 9602 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/18.json\n",
      "Filtered 8495 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/19.json\n",
      "Filtered 8624 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/2.json\n",
      "Filtered 8230 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/20.json\n",
      "Filtered 8502 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/21.json\n",
      "Filtered 8488 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/22.json\n",
      "Filtered 9413 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/23.json\n",
      "Filtered 8743 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/24.json\n",
      "Filtered 8619 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/25.json\n",
      "Filtered 8802 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/26.json\n",
      "Filtered 8763 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/27.json\n",
      "Filtered 10318 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/28.json\n",
      "Filtered 44783 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/29.json\n",
      "Filtered 8613 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/3.json\n",
      "Filtered 9118 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/30.json\n",
      "Filtered 8998 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/31.json\n",
      "Filtered 9122 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/32.json\n",
      "Filtered 9590 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/33.json\n",
      "Filtered 8659 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/34.json\n",
      "Filtered 9012 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/35.json\n",
      "Filtered 16531 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/36.json\n",
      "Filtered 10077 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/37.json\n",
      "Filtered 8853 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/38.json\n",
      "Filtered 8908 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/39.json\n",
      "Filtered 8513 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/4.json\n",
      "Filtered 9010 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/40.json\n",
      "Filtered 8943 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/41.json\n",
      "Filtered 9813 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/42.json\n",
      "Filtered 8628 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/43.json\n",
      "Filtered 8955 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/44.json\n",
      "Filtered 7827 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/45.json\n",
      "Filtered 8649 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/46.json\n",
      "Filtered 10909 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/47.json\n",
      "Filtered 10289 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/48.json\n",
      "Filtered 8566 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/49.json\n",
      "Filtered 10916 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/5.json\n",
      "Filtered 8743 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/50.json\n",
      "Filtered 8822 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/51.json\n",
      "Filtered 9172 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/52.json\n",
      "Filtered 9016 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/53.json\n",
      "Filtered 11121 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/54.json\n",
      "Filtered 10307 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/55.json\n",
      "Filtered 10292 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/56.json\n",
      "Filtered 8459 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/57.json\n",
      "Filtered 10542 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/58.json\n",
      "Filtered 9878 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/59.json\n",
      "Filtered 9033 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/6.json\n",
      "Filtered 8451 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/60.json\n",
      "Filtered 11325 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/61.json\n",
      "Filtered 10728 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/62.json\n",
      "Filtered 10004 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/63.json\n",
      "Filtered 9423 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/64.json\n",
      "Filtered 9579 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/65.json\n",
      "Filtered 10401 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/66.json\n",
      "Filtered 9541 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/67.json\n",
      "Filtered 9120 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/68.json\n",
      "Filtered 9806 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/69.json\n",
      "Filtered 8974 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/7.json\n",
      "Filtered 9600 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/70.json\n",
      "Filtered 9481 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/71.json\n",
      "Filtered 8214 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/72.json\n",
      "Filtered 9031 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/73.json\n",
      "Filtered 8794 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/74.json\n",
      "Filtered 9834 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/75.json\n",
      "Filtered 9949 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/76.json\n",
      "Filtered 9720 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/77.json\n",
      "Filtered 8777 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/78.json\n",
      "Filtered 8424 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/79.json\n",
      "Filtered 9771 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/8.json\n",
      "Filtered 8988 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/80.json\n",
      "Filtered 8080 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/81.json\n",
      "Filtered 8499 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/82.json\n",
      "Filtered 10400 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/83.json\n",
      "Filtered 9764 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/84.json\n",
      "Filtered 8955 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/85.json\n",
      "Filtered 9203 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/86.json\n",
      "Filtered 9087 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/87.json\n",
      "Filtered 9624 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/88.json\n",
      "Filtered 8407 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/89.json\n",
      "Filtered 9117 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/9.json\n",
      "Filtered 8617 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/90.json\n",
      "Filtered 9607 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/91.json\n",
      "Filtered 9655 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/92.json\n",
      "Filtered 9644 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/93.json\n",
      "Filtered 8126 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/94.json\n",
      "Filtered 8466 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/95.json\n",
      "Filtered 10014 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/96.json\n",
      "Filtered 9745 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/97.json\n",
      "Filtered 8924 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/98.json\n",
      "Filtered 8659 products\n",
      "Processing gs://ma-muy/baseline_dataset/filtered_users_and_sessions/99.json\n",
      "Filtered 10773 products\n",
      "{\n",
      "  \"num_users\": 307526,\n",
      "  \"num_sessions\": 6308790,\n",
      "  \"median_sessions_per_user\": 11.0,\n",
      "  \"mean_sessions_per_user\": 20.514655671390386,\n",
      "  \"std_sessions_per_user\": 31.848181210885368,\n",
      "  \"median_events_per_product\": 18,\n",
      "  \"mean_events_per_product\": 90.03553523601916,\n",
      "  \"std_events_per_product\": 476.7504084756792,\n",
      "  \"num_products\": 579847,\n",
      "  \"num_events\": 45908674,\n",
      "  \"median_events_per_session\": 5.0,\n",
      "  \"mean_events_per_session\": 7.276938049927165,\n",
      "  \"std_events_per_session\": 87.35137755469516\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def filter_products_and_collect_stats(input_dict, dataset_stats, products_to_filter, min_events_per_session):\n",
    "    \n",
    "    output_dict = dict()\n",
    "    num_filtered = 0\n",
    "    \n",
    "    dataset_stats['num_users'] += len(input_dict)\n",
    "    for user_id in input_dict:\n",
    "        sessions = 0\n",
    "        output_dict[user_id] = dict()\n",
    "        for session_id in input_dict[user_id]:\n",
    "\n",
    "            filtered_events = list(filter(lambda x: x['ProductId'] not in products_to_filter, input_dict[user_id][session_id]['Events']))\n",
    "            num_filtered += (len(input_dict[user_id][session_id]['Events']) - len(filtered_events))\n",
    "            if len(filtered_events) >= min_events_per_session:\n",
    "                sessions += 1\n",
    "                output_dict[user_id][session_id] = dict()\n",
    "                output_dict[user_id][session_id]['Events'] = filtered_events\n",
    "                output_dict[user_id][session_id]['StartTime'] = min(map(lambda x: int(x['Timestamp']), output_dict[user_id][session_id]['Events']))\n",
    "                dataset_stats['events_per_session'].append(len(filtered_events))\n",
    "        dataset_stats['sessions_per_user'].append(sessions)\n",
    "    print('Filtered {} products'.format(num_filtered))\n",
    "    return output_dict, dataset_stats\n",
    "\n",
    "##################################################################\n",
    "\n",
    "min_events_per_product = 5\n",
    "min_events_per_session = 3\n",
    "\n",
    "client = storage.Client.from_service_account_json('../../service-account.json')\n",
    "preprocessed_prefix = 'gs://ma-muy/baseline_dataset/filtered_users_and_sessions/'\n",
    "events_per_product = dict_ops.load_dict('events_per_product.json')\n",
    "products_to_filter = set(list(map(lambda x: int(x), filter(lambda x: events_per_product[x] < min_events_per_product, events_per_product))))\n",
    "\n",
    "print(\"Total Products:\", len(events_per_product.keys()))\n",
    "print(\"Products with low support:\", len(products_to_filter))\n",
    "      \n",
    "for product_id in products_to_filter:\n",
    "    _ = events_per_product.pop(str(product_id), None)\n",
    "\n",
    "dataset_stats = dict()\n",
    "dataset_stats['num_users'] = 0\n",
    "dataset_stats['events_per_session'] = []\n",
    "dataset_stats['events_per_product'] = events_per_product\n",
    "dataset_stats['sessions_per_user'] = []\n",
    "\n",
    "paths = get_paths_with_prefix(preprocessed_prefix)\n",
    "\n",
    "for path in paths:\n",
    "    print('Processing {}'.format(path))\n",
    "    input_dict = dict_ops.load_dict(path, gcs_client=client)\n",
    "    \n",
    "    output_dict, dataset_stats = filter_products_and_collect_stats(input_dict, dataset_stats, products_to_filter, min_events_per_session)\n",
    "    \n",
    "    output_path = path.replace('filtered_users_and_sessions', 'filtered_products')\n",
    "    dict_ops.save_dict(output_path, output_dict, gcs_client=client)\n",
    "\n",
    "dataset_stats['num_sessions'] = sum(dataset_stats['sessions_per_user'])\n",
    "dataset_stats['median_sessions_per_user'] = median(dataset_stats['sessions_per_user'])\n",
    "dataset_stats['mean_sessions_per_user'] = mean(dataset_stats['sessions_per_user'])\n",
    "dataset_stats['std_sessions_per_user'] = stdev(dataset_stats['sessions_per_user'])\n",
    "del dataset_stats['sessions_per_user']\n",
    "\n",
    "dataset_stats['median_events_per_product'] = median(dataset_stats['events_per_product'].values())\n",
    "dataset_stats['mean_events_per_product'] = mean(dataset_stats['events_per_product'].values())\n",
    "dataset_stats['std_events_per_product'] = stdev(dataset_stats['events_per_product'].values())\n",
    "dataset_stats['num_products'] = len(dataset_stats['events_per_product'].keys())\n",
    "del dataset_stats['events_per_product']\n",
    "\n",
    "dataset_stats['num_events'] = sum(dataset_stats['events_per_session'])\n",
    "dataset_stats['median_events_per_session'] = median(dataset_stats['events_per_session'])\n",
    "dataset_stats['mean_events_per_session'] = mean(dataset_stats['events_per_session'])\n",
    "dataset_stats['std_events_per_session'] = stdev(dataset_stats['events_per_session'])\n",
    "del dataset_stats['events_per_session']\n",
    "\n",
    "print(json.dumps(dataset_stats, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Train, Validation and Test Dataset\n",
    "\n",
    "- For each user keep the last session in the test set\n",
    "- The rest represents the training set\n",
    "- The last session of users in the training set is extracted again and used as the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate User Parallel Mini batches\n",
    "\n",
    "- Now that we know all the sessions of all the users we can generate the user parallel mini batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_iterator(sessions_by_user_prefix):\n",
    "    paths = get_paths_with_prefix(sessions_by_user_prefix)\n",
    "    for path in paths:\n",
    "        merged_shard = dict_ops.load_dict(path)\n",
    "        user_ids = list(merged_shard.keys())\n",
    "        random.shuffle(user_ids)\n",
    "        for user_id in user_ids:\n",
    "            yield user_id, merged_shard[user_id]\n",
    "\n",
    "def event_iterator(user_sessions, min_events_per_session):\n",
    "    sorted_sessions = sorted(map(lambda x: user_sessions[x], user_sessions.keys()), key=lambda y: y['StartTime'])\n",
    "    for sorted_session in sorted_sessions:\n",
    "        if len(sorted_session['Events']) < min_events_per_session:\n",
    "            continue\n",
    "            \n",
    "        sorted_events = sorted(sorted_session['Events'], key=lambda z: z['Timestamp'])\n",
    "        for event in sorted_events:\n",
    "            yield event['ProductId']\n",
    "        \n",
    "        yield '<EOS>'\n",
    "        \n",
    "def get_next_event_or_none(active_user):\n",
    "    try:\n",
    "        return next(active_user['Events'])\n",
    "    except StopIteration:\n",
    "        return None\n",
    "    \n",
    "def get_next_user_or_none(users, min_events_per_session):\n",
    "    try:\n",
    "        user_id, user_sessions = next(users)\n",
    "        return {\n",
    "            'UserId': int(user_id),\n",
    "            'Events': event_iterator(user_sessions, min_events_per_session)\n",
    "        }\n",
    "    except StopIteration:\n",
    "        return None\n",
    "        \n",
    "def user_parallel_batch_iterator(batch_size, sessions_by_user_prefix, min_events_per_session):\n",
    "\n",
    "        active_users = dict()\n",
    "        users = user_iterator(sessions_by_user_prefix)\n",
    "    \n",
    "        data = [[]]*batch_size\n",
    "\n",
    "        # Initial fill of users\n",
    "        for i in range(batch_size):\n",
    "            active_users[i] = get_next_user_or_none(users, min_events_per_session)\n",
    "        \n",
    "        while True:\n",
    "            next_batch = dict()\n",
    "            for idx in active_users:\n",
    "                if active_users[idx] is None:\n",
    "                    next_batch[idx] = ('<EOU>', '<EOS>')\n",
    "                    continue\n",
    "                next_event = get_next_event_or_none(active_users[idx])\n",
    "                while next_event is None:\n",
    "                    next_user = get_next_user_or_none(users, min_events_per_session)\n",
    "                    if next_user is None:\n",
    "                        print('There are no more new users')\n",
    "                        active_users[idx] = None\n",
    "                        break\n",
    "                    else:\n",
    "                        active_users[idx] = next_user\n",
    "                        next_event = get_next_event_or_none(active_users[idx])\n",
    "                else:\n",
    "                    next_batch[idx] = (active_users[idx]['UserId'], next_event)\n",
    "            if len(set(next_batch.values())) == 1:\n",
    "                return\n",
    "            yield list(next_batch.values())\n",
    "            \n",
    "####################################################\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "MIN_EVENTS_PER_SESSION = 5\n",
    "\n",
    "if TESTMODE:\n",
    "    sessions_by_user_prefix = 'sessions_by_user/'\n",
    "else:\n",
    "    sessions_by_user_prefix = 'gs://ma-muy/baseline_dataset/sessions_by_user/'\n",
    "iterator = user_parallel_batch_iterator(BATCH_SIZE, sessions_by_user_prefix, MIN_EVENTS_PER_SESSION)\n",
    "batches = []\n",
    "for idx, batch in enumerate(iterator):\n",
    "    batches.append(batch)\n",
    "    if idx == 200:\n",
    "        break\n",
    "pprint.PrettyPrinter(width=240, compact=True).pprint(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we have created the user parallel mini batches\n",
    "- This notebook can be split into two parts:\n",
    "    - First we have the export of the data and transformation into sessions by users\n",
    "    - Second we have the generation of the mini batches based on the sessions by users\n",
    "    \n",
    "- The first part should be implemented in a ETL Pipeline and will be executed daily\n",
    "- The second part is part of the dataset implementation inside the model repository"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
